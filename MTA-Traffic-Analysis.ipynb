{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing/cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from math import ceil\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import turnstile data\n",
    "This cell runs the script we created to easily import multiple weeks worth of data from the MTA website. Running the code will create an mta_data folder in the current directory which contains csv files for all the weeks between the date given as an argument and the most recent Saturday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_data as gd\n",
    "gd.main(['2020-12-01'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our primary Python modules\n",
    "These are the files that we created to streamline creating, cleaning and processing the data. In addition to functions to creating data frames, they also contain functions to create frames aggregated in a variety different ways and functions to add various metrics to the data frame.\n",
    "\n",
    "*Note: The wrangle_data module assumes that the mta data was imported with the get_data script, and thus looks for data in an mta_data folder in the current directory in the format produced by get_data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrangle_data as wd\n",
    "import get_metrics as gm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our main data frames for EDA: \n",
    "- df - contains the turnstile data, with unique ID's created for each turnstile, booth, and station. Also has added columns for metrics such as net entries and exits, traffic and turnstile count.\n",
    "    * The wd.run() function takes up to two optional arguments in the form 'YYYY-MM-DD' (Date mut be a Saturday). If no argument is given, it will return a data frame with data from the week ending in 06/27/2020. If one argument is given, will return a data frame with data from the week ending in the Saturday given. If two arguments are given, it will return a data frame with data from all the weeks between that of the first argument given and that of the second.\n",
    "- df_c - contains the above data frame merged with the data set we acquired with remote complex id information. \n",
    "- spt - contains the spatial data set we acquired, which has longitude and latitude coordinates for each station along with more info about the stations themselves. Unfortunately, we were unable to connect the two sets by station with the time we had, as that would require more language processing than we had time for. Therefore, we used the remote complex ID (added to the turnstile data in df_c) to connect the two sets. \n",
    "- key - contains a map with all complex IDs and the station IDs and names associated with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wd.run()\n",
    "df_c = wd.merge_complex(df)\n",
    "spt = wd.spt()\n",
    "key = df_c[['complex_id', 'suid', 'station']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'c_a', 'unit', 'scp', 'station_x', 'linename', 'division',\n",
       "       'desc', 'entries', 'exits', 'tuid', 'suid', 'buid', 'ts_count',\n",
       "       'net_entries', 'net_exits', 'traffic', 'booth', 'complex_id',\n",
       "       'station_y', 'line_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining our basic metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates a subset of the complex data frame containing only the most relevant columns. Then, it performs the following processes to further clean the data:\n",
    "- Creates a delta_time column in order to correct for inconsistent time stamps\n",
    "- Calculates traffic per hour for each turnstile\n",
    "- Rounds the datetime column to the frequency given in argument\n",
    "- For each timestamp, sums the traffic per hour to create a column contaning total traffic per hour of the station\n",
    "- For each timestamp, divides the total traffic per station by the number of turnstiles in that station in order to  approximate density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_calc(df, freq):\n",
    "    dens = df_c[['station', 'suid', 'tuid', 'datetime', 'traffic', 'ts_count']]\n",
    "    \n",
    "    #Create column with timedelta between current row and next row\n",
    "    dens['delta_time'] = dens.groupby(['suid', 'tuid'])['datetime'].diff().dt.seconds.shift(-1) / 3600\n",
    "    #drop the nulls that were created in the above step\n",
    "    dens = dens.dropna()\n",
    "    \n",
    "    #Round each datetime stamp to closest hour to make plotting much more simple\n",
    "    #Seriously this step reduces unique datetime values from ~11500 to 165\n",
    "    #The round function is only available for a datetime index, so need to temporarily make 'datetime' the index\n",
    "    dens = dens.set_index('datetime') \n",
    "    dens.index = dens.index.round('H')\n",
    "    dens.reset_index(inplace=True)\n",
    "    \n",
    "    #there are some columns where the delta_time is 0. We don't need these\n",
    "    dens = dens[dens['delta_time'] > 0]\n",
    "    \n",
    "    #Calculate average traffic per hour at each turnstile in each time interval \n",
    "    dens['trf_hr'] = dens['traffic'] / dens['delta_time']\n",
    "    \n",
    "    #Calculate total traffic per hour per station in each time interval \n",
    "    dens_traffic_tot = dens.groupby(['suid', 'datetime'])['trf_hr'].sum().reset_index()\n",
    "    dens_traffic_tot.rename(columns = {'trf_hr': 'total_traffic'}, inplace=True)\n",
    "    dens = dens.merge(dens_traffic_tot, on=['suid', 'datetime'], how='left')\n",
    "    \n",
    "    #Calculate traffic per turnstile per station in each time interval \n",
    "    dens['density'] = dens['total_traffic'] / dens['ts_count']\n",
    "    \n",
    "    #Now that we have the station average, return only one row per station w/ relevant columns\n",
    "    dens = dens[['datetime', 'station', 'suid', 'total_traffic', 'density']].drop_duplicates()\n",
    "    \n",
    "    return dens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary with keys from the unique station IDs and values containing data for all timestamps associated with the corresponding station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens_station = density_calc(df_c, 'H').set_index('suid')\n",
    "st_stats = {}\n",
    "for st in dens_stats_st.index.unique():\n",
    "    st_stats[dens_stats_st['suid'][st].unique()[0]] = dens_station[dens_station.index == st].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function generates and plots an array of subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_arr(df_dict, var, col_nums=10, title='', ylabel='', xlabel=''):\n",
    "    row_nums = ceil(len(df_dict) / col_nums)  # how many rows of plots\n",
    "    plt.figure(figsize=(40,100)) \n",
    "    \n",
    "    #create subplots for each station id in dict\n",
    "    for i, (k, v) in enumerate(df_dict.items(), 1):\n",
    "        plt.subplot(row_nums, col_nums, i)  \n",
    "        sub_v = v[var]\n",
    "        p = plt.stem(sub_v, markerfmt=' ', use_line_collection=True)\n",
    "        plt.title((title + k))\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlabel(xlabel)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this cell generates a large array of subplots, with each subplot corresponding to a single station and  containing a graph of total traffic vs datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_arr(st_stats, 'total_traffic', title='Station ID: ', xlabel='Date/time',\n",
    "        ylabel='Total traffic/hour in station')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this cell generates a large array of subplots, with each subplot corresponding to a single station and containing a graph of density vs datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_arr(st_stats, 'density', title='Station ID: ', xlabel='Date/time',\n",
    "        ylabel='Average density/hour in station')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates two dictionaries with keys from each unique timestamp and values containing data from all stations for that specific timestamp. In one dictionary, the stations are sorted by total_traffic, while in the other, the stations are sorted by density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dens_time = density_calc(df_c, '2H').set_index('datetime')\n",
    "\n",
    "total_sort = dens_time.reset_index().sort_values(['datetime','total_traffic']).set_index('datetime')\n",
    "density_sort = dens_time.reset_index().sort_values(['datetime','density']).set_index('datetime')\n",
    "\n",
    "time_total = {}\n",
    "for ti in total_sort.index.unique():\n",
    "    #some timeslots only have data from a few stations so let's ignore those\n",
    "    if (total_sort[total_sort.index == ti]['suid'].nunique() > 10):\n",
    "        time_total[ti] = total_sort[total_sort.index == ti].reset_index(drop=True)\n",
    "        \n",
    "time_dens = {}\n",
    "for ti in density_sort.index.unique():\n",
    "    #some timeslots only have data from a few stations so let's ignore those\n",
    "    if (density_sort[density_sort.index == ti]['suid'].nunique() > 10):\n",
    "        time_dens[ti] = density_sort[density_sort.index == ti].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this cell generates a large array of subplots, with each subplot corresponding to a single timestamp and containing a graph of total traffic vs stations, with stations sorted by total traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_arr(time_total, 'total_traffic', title='Date/time: ', xlabel='Stations sorted by total traffic',\n",
    "        ylabel='Total traffic/hour in station', col_nums=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this cell generates a large array of subplots, with each subplot corresponding to a single timestamp and containing a graph of density vs stations, with stations sorted by total traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_arr(time_total, 'density', title='Date/time: ', xlabel='Stations sorted by total traffic',\n",
    "        ylabel='Density of station', col_nums=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this cell generates a large array of subplots, with each subplot corresponding to a single timestamp and containing a graph of total traffic vs stations, with stations sorted by density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_arr(time_total, 'total_traffic', title='Date/time: ', xlabel='Stations sorted by density',\n",
    "        ylabel='Total traffic/hour in station', col_nums=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this cell generates a large array of subplots, with each subplot corresponding to a single timestamp and containing a graph of density vs stations, with stations sorted by density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_arr(time_total, 'density', title='Date/time: ', xlabel='Stations sorted by density',\n",
    "        ylabel='Density of station', col_nums=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dens_time_wk = density_calc(df_c, '2H').set_index('datetime')\n",
    "dens_time_wk = dens_time_wk.groupby('suid')[['total_traffic', 'density']].sum()\n",
    "\n",
    "total_sort_wk = dens_time.sort_values('total_traffic')\n",
    "density_sort_wk = dens_time.sort_values('density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this cell generates two subplots, with total traffic and density (respectively) plotted by station, with stations sorted by total traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30,30))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "p = plt.stem(total_sort_wk['total_traffic'], markerfmt=' ', use_line_collection=True)\n",
    "plt.title('Total traffic per station', fontsize=35)\n",
    "plt.ylabel('Total traffic/hour weekly average for ea. station', fontsize = 30)\n",
    "plt.xlabel('Stations sorted by total weekly traffic', fontsize = 30)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "p = plt.stem(total_sort_wk['density'], markerfmt=' ', use_line_collection=True)\n",
    "plt.title('Density per station', fontsize=35)\n",
    "plt.ylabel('Density/hour weekly average for ea. station', fontsize = 30)\n",
    "plt.xlabel('Stations sorted by total weekly traffic', fontsize = 30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this cell generates two subplots, with total traffic and density (respectively) plotted by station, with stations sorted by density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30,30))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "p = plt.stem(density_sort_wk['total_traffic'], markerfmt=' ', use_line_collection=True)\n",
    "plt.title('Total traffic per station', fontsize=35)\n",
    "plt.ylabel('Total traffic/hour weekly average for ea. station', fontsize = 30)\n",
    "plt.xlabel('Stations sorted by density', fontsize = 30)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "p = plt.stem(density_sort_wk['density'], markerfmt=' ', use_line_collection=True)\n",
    "plt.title('Density per station', fontsize=35)\n",
    "plt.ylabel('Density/hour weekly average for ea. station', fontsize = 30)\n",
    "plt.xlabel('Stations sorted by density', fontsize = 30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primary Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of ridership over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation between traffic and density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing a Priority Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_avg = density_calc(df_c, 'min').set_index('datetime')\n",
    "daily_avg['date'] = density_calc.index.date\n",
    "daily_avg = daily_avg.groupby(['suid', 'date'])[['total_traffic', 'density']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def priority(df):\n",
    "    #Calculate priority score\n",
    "    traf_top = df['traffic'].max()\n",
    "    dens_top = df['density'].max()\n",
    "    traffic_weight, density_weight = 0, 0\n",
    "    tra_score = (df['traffic'] / traf_top) \n",
    "    dens_score = (df['density'] / dens_top) \n",
    "    df['priority'] = (tra_score + traffic_weight) * (dens_score + density_weight)\n",
    "\n",
    "    #normalize priority score\n",
    "    p_min = df_daily_avg['priority'].min()\n",
    "    p_max = df_daily_avg['priority'].max()\n",
    "    p_range = p_max - p_min\n",
    "    df['priority']=(df['priority']-p_min)/(p_range)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_avg = priority(daily_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scope\n",
    "## % of total traffic in top n station by priority order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passing Data to CSV for Mapping (by complex ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = wd.run('2020-05-02', '2020-06-27')\n",
    "df_c_all = wd.merge_complex(df_all)\n",
    "\n",
    "#aggregate by complex id and date\n",
    "df_daily_co = wd.agg_by(df_c_all, 'date', 'complex')\n",
    "\n",
    "#create a turnstile count/complex column\n",
    "df_cc = df_c.groupby('complex_id')['tuid'].nunique().to_dict()\n",
    "df_daily_co['ts_count'] = df_daily_co.complex_id.map(df_cc)\n",
    "\n",
    "#calculate density\n",
    "df_daily_co['density'] = df_daily_co['traffic'] / df_daily_co['ts_count']\n",
    "\n",
    "#calculate average traffic and density figures for entire date range\n",
    "df_daily_co = df_daily_co.groupby('complex_id')[['traffic', 'density']].mean()\n",
    "\n",
    "#calculate priority scores\n",
    "df_daily_co = priority(df_daily_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export data to csv's so John can implement mapping\n",
    "df_daily_avg['traffic'].to_csv(path_or_buf='complex_traffic.csv', index=True)\n",
    "df_daily_avg['density'].to_csv(path_or_buf='complex_density.csv', index=True)\n",
    "df_daily_avg['priority'].to_csv(path_or_buf='complex_priority.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
